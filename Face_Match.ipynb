{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "objective: To compare two faces'\n",
        "\n",
        "General Approach\n",
        "1. Face Detection\n",
        "2. Alignment\n",
        "3. Face Description\n",
        "4. Face Recognition\n",
        "\n"
      ],
      "metadata": {
        "id": "aAv4br5AlB7f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First Approach:  Face Detection By Cascade Classifier and face similarity using MSE and SSIM"
      ],
      "metadata": {
        "id": "6rTVm9fAk44m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Importing the Packages\n",
        "\n",
        "import cv2\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "iw-Vevsjldr1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(imageA, imageB):\n",
        "  err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
        "  err= float(imageA.shape[0] * imageA.shape[1])\n",
        "  print(err)\n",
        "  return err\n",
        "\n",
        "\n",
        "def compare_images(imageA, imageB, title):\n",
        "  mt = mse(imageA, imageB)\n",
        "  st = ssim(imageA, imageB)\n",
        "\t# setup the figure\n",
        "  fig = plt.figure(title)\n",
        "  plt.suptitle(\"MSE: %.2f, SSIM: %.2f\" % (mt, st))\n",
        "\t# show first image\n",
        "  ax = fig.add_subplot(1, 2, 1)\n",
        "  plt.imshow(imageA, cmap = plt.cm.gray)\n",
        "  plt.axis(\"off\")\n",
        "\t# show the second image\n",
        "  ax = fig.add_subplot(1, 2, 2)\n",
        "  plt.imshow(imageB, cmap = plt.cm.gray)\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()\n",
        "  return([mt,st])"
      ],
      "metadata": {
        "id": "ZUGUBA3wnjHu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files=[\"/content/4x6.jpg\",\"/content/Ananya_photo.JPG\",\"/content/ankit_photo_4x6.jpg\",\"/content/mummy_adhar.png\",\n",
        "\"/content/mummy_photo.png\",\"/content/tunnu_photo.jpeg\"]\n",
        "\n",
        "import itertools\n",
        "files_com=[]\n",
        "for i, j in itertools.combinations_with_replacement(files, 2):\n",
        "  tiff=[i,j]\n",
        "  files_com.append(tiff)"
      ],
      "metadata": {
        "id": "lw1E1yJEluy3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(files_com)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW7X100hmYas",
        "outputId": "ef6d5b12-9c95-4d02-8842-5563568f00aa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_img(img1,img2):\n",
        "  width, height = img1.shape[0],img1.shape[1]\n",
        "  width_2, height_2=img2.shape[0],img2.shape[1]\n",
        "  if width>=width_2 or height>=height_2:\n",
        "    img1= cv2.resize(img1,(img2.shape[1],img2.shape[0]))\n",
        "  else:\n",
        "    img2= cv2.resize(img2,(img1.shape[1],img1.shape[0]))\n",
        "  #plt.imshow(img2)\n",
        "  plt.imshow(img1)\n",
        "  return([img1,img2])\n",
        ""
      ],
      "metadata": {
        "id": "x_4UrQ1RoFK6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_t=[]\n",
        "for i in files_com:\n",
        "  face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "  # images to grayscale\n",
        "  img1=cv2.imread(i[0])\n",
        "  img2=cv2.imread(i[1])\n",
        "  gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
        "  gray2= cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "  gray=[gray1,gray2]\n",
        "\n",
        "  # detect faces in the 2 images\n",
        "  faces1 = face_cascade.detectMultiScale(gray1, 1.3, 5)\n",
        "  faces2 = face_cascade.detectMultiScale(gray2, 1.3, 5)\n",
        "  roi_gray=[]\n",
        "  roi_color=[]\n",
        "\n",
        "  size=gray1.shape\n",
        "\n",
        "  # crop out only the face of the first and second images\n",
        "  for (x,y,w,h) in faces1:\n",
        "\n",
        "      extra=int(w/6)\n",
        "      x1=max(0,x-extra)\n",
        "      y1=max(0,y-extra)\n",
        "      x2=min(size[1],x1+2*extra+w)\n",
        "      y2=min(size[0],y1+2*extra+w)\n",
        "\n",
        "      img1 = cv2.rectangle(img1,(x1,y1),(x2-1,y2-1),(0,0,255),4)\n",
        "      roi_gray .append(gray1[y1:y2, x1:x2])\n",
        "      roi_color .append(img1[y1:y2, x1:x2])\n",
        "\n",
        "  if len(faces1)==0:\n",
        "    roi_gray .append(gray1)\n",
        "    roi_color .append(img1)\n",
        "\n",
        "  size=gray2.shape\n",
        "  for (x,y,w,h) in faces2:\n",
        "\n",
        "      extra=int(w/6)\n",
        "      x1=max(0,x-extra)\n",
        "      y1=max(0,y-extra)\n",
        "      x2=min(size[1],x1+2*extra+w)\n",
        "      y2=min(size[0],y1+2*extra+w)\n",
        "\n",
        "      img2 = cv2.rectangle(img2,(x1,y1),(x2-1,y2-1),(0,0,255),4)\n",
        "      roi_gray .append(gray2[y1:y2, x1:x2])\n",
        "      roi_color .append(img2[y1:y2, x1:x2])\n",
        "\n",
        "  if len(faces2)==0:\n",
        "    roi_gray .append(gray2)\n",
        "    roi_color .append(img2)\n",
        "\n",
        "  # img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
        "  # roi_color=cv2.cvtColor(roi_color,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # plot the cropped out grayscale images of the originals\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.imshow(roi_gray[0],cmap='gray', vmin=0, vmax=255)\n",
        "  plt.title('ROI of image 1')\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.imshow(roi_gray[1],cmap='gray', vmin=0, vmax=255)\n",
        "  plt.title('ROI of image 2')\n",
        "  plt.show()\n",
        "\n",
        "  img1_sizet=resize_img(roi_gray[0],roi_gray[1])[0]\n",
        "  print(img1_sizet.shape)\n",
        "  img2_sizet=resize_img(roi_gray[0],roi_gray[1])[1]\n",
        "  print(img2_sizet.shape)\n",
        "  plt.imshow(img2_sizet)\n",
        "  com=compare_images(img1_sizet,img2_sizet,\"MSE and SSIM\")\n",
        "  tz=[i[0],i[1],com[0],com[1]]\n",
        "  error_t.append(tz)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9JdEEU1nmfZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dfj=pd.DataFrame(error_t)"
      ],
      "metadata": {
        "id": "rXhrSvKVlqLm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfj.columns=[\"Image1\",\"Image2\",\"MSE\",\"SSIM\"]"
      ],
      "metadata": {
        "id": "kedkWFn7035m"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfj.to_csv(\"Different_Similarity_measures_for_face_match\",index=False)"
      ],
      "metadata": {
        "id": "5BPXteSy1tOY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approach 2: Face Recogintion"
      ],
      "metadata": {
        "id": "BAEAPo6x1_U0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install face_recognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTpov0PG2Xlf",
        "outputId": "47f5049e-f5b6-44ad-c89b-2cf74367e70d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.3)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.4.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566173 sha256=9fef2733dcfad290cc07fcb23a7a4e0692fd40d02f6d175649bf419d997c9748\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import face_recognition\n",
        "face_reco=[]\n",
        "for i in files_com:\n",
        "  img_modi = face_recognition.load_image_file(i[0])\n",
        "  img_modi = cv2.cvtColor(img_modi,cv2.COLOR_BGR2RGB)\n",
        "  #------to find the face location\n",
        "  face = face_recognition.face_locations(img_modi)[0]\n",
        "  print(face)\n",
        "  #--Converting image into encodings\n",
        "  train_encode = face_recognition.face_encodings(img_modi)[0]\n",
        "  #----- lets test an image\n",
        "  test = face_recognition.load_image_file(i[1])\n",
        "  test = cv2.cvtColor(test, cv2.COLOR_BGR2RGB)\n",
        "  test_encode = face_recognition.face_encodings(test)[0]\n",
        "  face_test=face_recognition.face_locations(test)[0]\n",
        "  tz=face_recognition.compare_faces([train_encode],test_encode)\n",
        "  print(face_recognition.compare_faces([train_encode],test_encode))\n",
        "  cv2.rectangle(img_modi, (face[3], face[0]),(face[1], face[2]), (255,0,255), 1)\n",
        "  cv2.rectangle(test, (face_test[3], face_test[0]),(face_test[1], face_test[2]), (255,0,255), 1)\n",
        "  from google.colab.patches import cv2_imshow\n",
        "  cv2_imshow(img_modi)\n",
        "  cv2_imshow(test)\n",
        "  tf=[i[0],i[1],tz]\n",
        "  face_reco.append(tf)\n"
      ],
      "metadata": {
        "id": "9kBqssqM199n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "face_reco_df=pd.DataFrame(face_reco)"
      ],
      "metadata": {
        "id": "7IX-CVmv2oUP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_reco_df.columns=[\"Image1\",\"Image2\",\"Face_recognition_model\"]"
      ],
      "metadata": {
        "id": "2MiotAGR7tkl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfj_t=pd.merge(dfj,face_reco_df,on=[\"Image1\",\"Image2\"],how=\"left\")"
      ],
      "metadata": {
        "id": "kiRdBgVD792G"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfj_t.to_csv(\"Face_Match_measures.csv\",index=False)"
      ],
      "metadata": {
        "id": "9cECp1DV8KDP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approach 3:  Using SIFT algorithm"
      ],
      "metadata": {
        "id": "1C5RoArK8uZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sift_t=[]\n",
        "for i in files_com:\n",
        "  print(i[0],i[1])\n",
        "  img1=cv2.imread(i[0])\n",
        "  img2 = cv2.imread(i[1])\n",
        "\n",
        "  # img1=cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
        "  # img2=cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # convert the images from bgr to rgb\n",
        "  img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
        "  img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "  # images to grayscale\n",
        "  gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
        "  gray2= cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "  gray=[gray1,gray2]\n",
        "\n",
        "  # detect faces in the 2 images\n",
        "  faces1 = face_cascade.detectMultiScale(gray1, 1.1, 5)\n",
        "  faces2 = face_cascade.detectMultiScale(gray2, 1.1, 5)\n",
        "  roi_gray=[]\n",
        "  roi_color=[]\n",
        "\n",
        "  size=gray1.shape\n",
        "\n",
        "  # crop out only the face of the first and second images\n",
        "  for (x,y,w,h) in faces1:\n",
        "\n",
        "      extra=int(w/6)\n",
        "      x1=max(0,x-extra)\n",
        "      y1=max(0,y-extra)\n",
        "      x2=min(size[1],x1+2*extra+w)\n",
        "      y2=min(size[0],y1+2*extra+w)\n",
        "\n",
        "      img1 = cv2.rectangle(img1,(x1,y1),(x2-1,y2-1),(0,0,255),4)\n",
        "      roi_gray .append(gray1[y1:y2, x1:x2])\n",
        "      roi_color .append(img1[y1:y2, x1:x2])\n",
        "\n",
        "  if len(faces1)==0:\n",
        "    roi_gray .append(gray1)\n",
        "    roi_color .append(img1)\n",
        "\n",
        "  size=gray2.shape\n",
        "  for (x,y,w,h) in faces2:\n",
        "\n",
        "      extra=int(w/6)\n",
        "      x1=max(0,x-extra)\n",
        "      y1=max(0,y-extra)\n",
        "      x2=min(size[1],x1+2*extra+w)\n",
        "      y2=min(size[0],y1+2*extra+w)\n",
        "\n",
        "      img2 = cv2.rectangle(img2,(x1,y1),(x2-1,y2-1),(0,0,255),4)\n",
        "      roi_gray .append(gray2[y1:y2, x1:x2])\n",
        "      roi_color .append(img2[y1:y2, x1:x2])\n",
        "\n",
        "  if len(faces2)==0:\n",
        "    roi_gray .append(gray2)\n",
        "    roi_color .append(img2)\n",
        "\n",
        "  sift = cv2.SIFT_create()\n",
        "\n",
        "  kp1, des1 = sift.detectAndCompute(roi_gray[0],None)\n",
        "  kp2, des2 = sift.detectAndCompute(roi_gray[1],None)\n",
        "\n",
        "  # create a bruteforce matcher\n",
        "  bf = cv2.BFMatcher()\n",
        "\n",
        "  matches=bf.knnMatch(des1,des2,k=2)\n",
        "\n",
        "\n",
        "  good = []\n",
        "  for m,n in matches:\n",
        "    #print(m.distance,n.distance)\n",
        "    if m.distance < 0.75*n.distance:\n",
        "      good.append([m])\n",
        "\n",
        "  img3 = cv2.drawMatchesKnn(roi_gray[0],kp1,roi_gray[1],kp2,good,None,flags=2)\n",
        "\n",
        "  # decide whether the images are a match or not based on the number of good matches.\n",
        "  # Yes, crude but a good starting intuition\n",
        "  if len(good)>=30:\n",
        "    z=\"It's a Match\"\n",
        "    print(\"It's a Match\")\n",
        "\n",
        "  else:\n",
        "    z=\"Not a Match\"\n",
        "    print(\"Not a Match\")\n",
        "\n",
        "  tef=[i[0],i[1],z]\n",
        "  sift_t.append(tef)\n",
        "\n",
        "  plt.figure(figsize=(40,20))\n",
        "  plt.imshow(img3)\n",
        "  plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "OqVM7b4r8gzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sift_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0S0dBLr9QPB",
        "outputId": "ae76baf6-9fff-4cc8-d3fa-03ecc653ec77"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['/content/4x6.jpg', '/content/4x6.jpg', \"It's a Match\"],\n",
              " ['/content/4x6.jpg', '/content/Ananya_photo.JPG', 'Not a Match'],\n",
              " ['/content/4x6.jpg', '/content/ankit_photo_4x6.jpg', 'Not a Match'],\n",
              " ['/content/4x6.jpg', '/content/mummy_adhar.png', 'Not a Match'],\n",
              " ['/content/4x6.jpg', '/content/mummy_photo.png', 'Not a Match'],\n",
              " ['/content/4x6.jpg', '/content/tunnu_photo.jpeg', 'Not a Match'],\n",
              " ['/content/Ananya_photo.JPG', '/content/Ananya_photo.JPG', \"It's a Match\"],\n",
              " ['/content/Ananya_photo.JPG', '/content/ankit_photo_4x6.jpg', 'Not a Match'],\n",
              " ['/content/Ananya_photo.JPG', '/content/mummy_adhar.png', 'Not a Match'],\n",
              " ['/content/Ananya_photo.JPG', '/content/mummy_photo.png', 'Not a Match'],\n",
              " ['/content/Ananya_photo.JPG', '/content/tunnu_photo.jpeg', 'Not a Match'],\n",
              " ['/content/ankit_photo_4x6.jpg',\n",
              "  '/content/ankit_photo_4x6.jpg',\n",
              "  \"It's a Match\"],\n",
              " ['/content/ankit_photo_4x6.jpg', '/content/mummy_adhar.png', 'Not a Match'],\n",
              " ['/content/ankit_photo_4x6.jpg', '/content/mummy_photo.png', 'Not a Match'],\n",
              " ['/content/ankit_photo_4x6.jpg', '/content/tunnu_photo.jpeg', 'Not a Match'],\n",
              " ['/content/mummy_adhar.png', '/content/mummy_adhar.png', \"It's a Match\"],\n",
              " ['/content/mummy_adhar.png', '/content/mummy_photo.png', 'Not a Match'],\n",
              " ['/content/mummy_adhar.png', '/content/tunnu_photo.jpeg', 'Not a Match'],\n",
              " ['/content/mummy_photo.png', '/content/mummy_photo.png', 'Not a Match'],\n",
              " ['/content/mummy_photo.png', '/content/tunnu_photo.jpeg', 'Not a Match'],\n",
              " ['/content/tunnu_photo.jpeg', '/content/tunnu_photo.jpeg', \"It's a Match\"]]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SIFT_t=pd.DataFrame(sift_t)"
      ],
      "metadata": {
        "id": "CEF6gQY29hS1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SIFT_t.columns=[\"Image1\",\"Image2\",\"SIFT_MATCH\"]"
      ],
      "metadata": {
        "id": "Banx9AmT-J6I"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfj_t=pd.merge(dfj_t,SIFT_t,on=[\"Image1\",\"Image2\"],how=\"left\")"
      ],
      "metadata": {
        "id": "ybuZYFUh-3h5"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfj_t.to_csv(\"Face_Match_measures_new.csv\",index=False)"
      ],
      "metadata": {
        "id": "TFx-4b5N_FZJ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using DeepFace Algorithm"
      ],
      "metadata": {
        "id": "ySybll0CE00l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install deepface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4jEfz0DExji",
        "outputId": "96905b89-2987-4700-af6a-2d6ff75abb99"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepface\n",
            "  Downloading deepface-0.0.79-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.65.0)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.6.6)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (8.4.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.7.0.72)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.12.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.12.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.2.4)\n",
            "Collecting mtcnn>=0.1.0 (from deepface)\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting retina-face>=0.0.1 (from deepface)\n",
            "  Downloading retina_face-0.0.13-py3-none-any.whl (16 kB)\n",
            "Collecting fire>=0.4.0 (from deepface)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gunicorn>=20.1.0 (from deepface)\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (2.3.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.3.0)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (8.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (2.27.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (4.11.2)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.10/dist-packages (from gunicorn>=20.1.0->deepface) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2022.7.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.4.10)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.20.3)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=1.9.0->deepface) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=1.9.0->deepface) (1.10.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=1.1.2->deepface) (2.1.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (1.8.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (3.2.2)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116932 sha256=d20594617be77151ca537833e1f137cbc930a0dd6607bd8e1f83324299dcc5cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: gunicorn, fire, mtcnn, retina-face, deepface\n",
            "Successfully installed deepface-0.0.79 fire-0.5.0 gunicorn-20.1.0 mtcnn-0.1.1 retina-face-0.0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from deepface import DeepFace\n",
        "models = [\n",
        "  \"VGG-Face\",\n",
        "  \"Facenet\",\n",
        "  \"Facenet512\",\n",
        "  \"OpenFace\",\n",
        "  \"DeepFace\",\n",
        "  \"ArcFace\",\n",
        "  \"Dlib\"\n",
        "]\n",
        "\n",
        "deep=[]\n",
        "for j in range(len(models)):\n",
        "  for i in files_com:\n",
        "    img1=i[0]\n",
        "    img2=i[1]\n",
        "    obj=DeepFace.verify(img1,img2,model_name = models[j])\n",
        "    tef=[models[j],i[0], i[1], obj['verified']]\n",
        "    deep.append(tef)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEs0oQWi_Lo7",
        "outputId": "82ae4aa2-c0e0-4e0b-bb30-9d66ce93629e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arcface_weights.h5  will be downloaded to  /root/.deepface/weights/arcface_weights.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/arcface_weights.h5\n",
            "To: /root/.deepface/weights/arcface_weights.h5\n",
            "100%|██████████| 137M/137M [00:00<00:00, 223MB/s]\n",
            "Downloading...\n",
            "From: http://dlib.net/files/dlib_face_recognition_resnet_model_v1.dat.bz2\n",
            "To: /root/.deepface/weights/dlib_face_recognition_resnet_model_v1.dat.bz2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlib_face_recognition_resnet_model_v1.dat is going to be downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21.4M/21.4M [00:00<00:00, 33.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deepface=pd.DataFrame(deep)"
      ],
      "metadata": {
        "id": "n-iu-WL7IAEg"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deepface.to_csv(\"DeepFace_results.csv\",index=False)"
      ],
      "metadata": {
        "id": "u-ASXJhNITvf"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mHxWDaszIZbo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}